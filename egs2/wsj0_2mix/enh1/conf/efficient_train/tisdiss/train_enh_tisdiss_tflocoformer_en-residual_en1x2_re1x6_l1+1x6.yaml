# Copyright (C) 2024 Mitsubishi Electric Research Laboratories (MERL)
#
# SPDX-License-Identifier: Apache-2.0


# Takes ~4.5 days using 4 RTX 2080Ti
init: xavier_uniform
max_epoch: 150
use_amp: false
batch_type: folded
batch_size: 6  # batch size of 4 on each H800 GPU of 80 GB
valid_batch_size: 16
num_workers: 16
num_att_plot: 0
# preprocessor
preprocessor: enh
num_spk: &num_spk 2
iterator_type: sequence # not to discard short samples
speech_segment: 32000
shuffle_within_batch: true

# espnet model configuration
model_conf:
    normalize_variance: true

# optimizer and scheduler
optim: adamw
optim_conf:
    lr: 1.0e-03
    eps: 1.0e-08
    weight_decay: 1.0e-02
patience: 10
val_scheduler_criterion:
- valid
- loss
best_model_criterion:
-   - valid
    - si_snr
    - max
-   - valid
    - loss
    - min
keep_nbest_models: 5
scheduler: warmupreducelronplateau
scheduler_conf:
    warmup_steps: 2000 # 4000 for batch size 4, 2000 for batch size 8
    mode: min
    factor: 0.5
    patience: 3

# model configuration
encoder: &encoder stft
encoder_conf:
    n_fft: &n_fft 128
    hop_length: &hop_length 64
decoder: *encoder
decoder_conf:
    n_fft: *n_fft
    hop_length: *hop_length
separator: tisdiss
separator_conf:
    num_spk: *num_spk
    # general setup
    emb_dim: 128
    norm_type: rmsgroupnorm
    num_groups: 4
    tf_order: ft
    # self-attention
    n_heads: 4
    flash_attention: false
    # ffn
    ffn_type:
        - swiglu_conv1d
        - swiglu_conv1d
    ffn_hidden_dim:
        - 384
        - 384 # list order must be the same as ffn_type
    conv1d_kernel: 4
    conv1d_shift: 1
    dropout: 0.0
    # others
    eps: 1.0e-5
    # efficient training related
    # en1x2 = encoder_n_layers * encoder_repeat_times = 1 * 2 = 2
    # encoder transformer blocks = 2 * encoder_n_layers * encoder_repeat_times = 2 * 1 * 2 = 4
    encoder_repeat_times: 2 
    encoder_n_layers: 1
    # re1x3 = reconstructor_n_layers * reconstructor_repeat_times = 1 * 3 = 3
    # reconstructor transformer blocks = 3 * reconstructor_n_layers * reconstructor_repeat_times = 3 * 1 * 3 = 9
    reconstructor_repeat_times: 6
    reconstructor_n_layers: 1
    repeat_residual_module: true
    reconstructor_repeat_residual_module: false
    # early split and multi decoder related
    encoder_decoder: false
    encoder_multi_decoder: false
    encoder_n_layers_multi_decoder: false
    reconstructor_multi_decoder: true
    reconstructor_n_layers_multi_decoder: true
    spliter_loss: true

criterions:
    # The first criterion
  - name: si_snr
    conf:
        eps: 1.0e-7
    wrapper: pit
    wrapper_conf:
        weight: 1.0
        independent_perm: true
